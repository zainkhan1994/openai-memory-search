Traceback (most recent call last):
  File "/Users/zainkhan/May 21/all_openai_exports/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1014, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/zainkhan/May 21/all_openai_exports/.venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/zainkhan/May 21/all_openai_exports/openai-memory-search/build_convo_index.py", line 55, in <module>
    summary = summarize(full_text)
  File "/Users/zainkhan/May 21/all_openai_exports/openai-memory-search/build_convo_index.py", line 40, in summarize
    out = client.chat.completions.create(
        model="gpt-4",
    ...<3 lines>...
        ]
    )
  File "/Users/zainkhan/May 21/all_openai_exports/.venv/lib/python3.13/site-packages/openai/_utils/_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "/Users/zainkhan/May 21/all_openai_exports/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py", line 925, in create
    return self._post(
           ~~~~~~~~~~^
        "/chat/completions",
        ^^^^^^^^^^^^^^^^^^^^
    ...<43 lines>...
        stream_cls=Stream[ChatCompletionChunk],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/zainkhan/May 21/all_openai_exports/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1239, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/zainkhan/May 21/all_openai_exports/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1020, in request
    self._sleep_for_retry(
    ~~~~~~~~~~~~~~~~~~~~~^
        retries_taken=retries_taken,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        response=response,
        ^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/Users/zainkhan/May 21/all_openai_exports/.venv/lib/python3.13/site-packages/openai/_base_client.py", line 1060, in _sleep_for_retry
    time.sleep(timeout)
    ~~~~~~~~~~^^^^^^^^^
KeyboardInterrupt
